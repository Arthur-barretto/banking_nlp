{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbnu_4n4ipbW"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhbMZvGcMSlH",
        "outputId": "a1113fb9-8101-4eb0-8278-c2a8ac6616ef"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g12xGqNBMsKU",
        "outputId": "552cbd01-de4a-4066-9941-4c4d489840d1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "!pip install pdfplumber\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import concurrent.futures\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6HaUwAlDIEi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#torch.cuda.is_available()\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioFoEjLki08t"
      },
      "source": [
        "#### Call Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3BsO5G2VXp_"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "\n",
        "    text = text.replace(\"\\n\", ' ')\n",
        "    text = text.replace(\"”\", '')\n",
        "    text = text.replace(\"“\", '')\n",
        "    text = text.replace(\"\\\"\", '')\n",
        "    text = text.replace(\"\", '')\n",
        "\n",
        "    #lista com bolinha\n",
        "    text = re.sub(r'(\\s)?(;\\s)?(•)', \"; \", text.strip())\n",
        "    text = re.sub(r'(: ;)', \": \", text.strip())\n",
        "    text = re.sub(r'(\\.;)', \". \", text.strip())\n",
        "\n",
        "    # nu-2021-4T21-Script 4T21.pdf\n",
        "    text = re.sub(r'(; -)', \". \", text.strip())\n",
        "    text = re.sub(r'(\\. -)', \". \", text.strip())\n",
        "    text = re.sub(r'^(-)', \"\", text.strip())\n",
        "    text = re.sub(r'(: \\d.)', ': .', text.strip())\n",
        "    text = re.sub(r'(; e (\\d+\\.)?)', '.', text.strip())\n",
        "    text = re.sub(r'(: ●)', '.', text.strip())\n",
        "    text = re.sub(r'(; ●)', '.', text.strip())\n",
        "    text = re.sub(r'(●)', '', text.strip())\n",
        "\n",
        "    text = re.sub(\"_______________________________________________________________\", \"\", text)\n",
        "\n",
        "    text = re.sub(r\"Sra\\.\", \"Senhora \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"Sr\\.\", \"Senhor \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"Srs\\.\", \"Senhores \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'b\\.p\\.\\s([A-Z])', 'bp. \\\\1', text).strip()\n",
        "    text = re.sub('b.p.', 'bp', text).strip()\n",
        "    text = re.sub('p.p.', 'pp', text).strip()\n",
        "    text = re.sub('help!', 'help', text).strip() # bmgb -> tirar a exclamação para evitar quebra de sentenças\n",
        "\n",
        "    text = re.sub('\\s+', ' ', text).strip() # deixar por ultimo, pois as substituicoes anteriores podem inserir multiplos espaços\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StxKB28IVeeH"
      },
      "outputs": [],
      "source": [
        "def get_sentences(text):\n",
        "    sentences = sent_tokenize(text, language='portuguese')\n",
        "    sentences = [s for s in sentences if len(s.strip()) > 2]\n",
        "    return sentences\n",
        "\n",
        "def get_tokens(text):\n",
        "    tokens = word_tokenize(text, language='portuguese')\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def get_words(text):\n",
        "    tokens = get_tokens(text)\n",
        "\n",
        "    words = [w for w in tokens if w not in string.punctuation]\n",
        "\n",
        "    return words\n",
        "\n",
        "def save_text(filename, sentences):\n",
        "    with open(filename, 'w') as f:\n",
        "        for row in sentences:\n",
        "            if row != '':\n",
        "                f.write(row+'\\n')\n",
        "\n",
        "def generate_stats(text):\n",
        "    stats = {}\n",
        "    tokens = get_tokens(text)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    stats[\"tokens\"] = num_tokens\n",
        "\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bNQK1xe1iFp"
      },
      "source": [
        "#### Pattern Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-SUax-gBJG"
      },
      "outputs": [],
      "source": [
        "def split_text(text):\n",
        "  # Define patterns to identify the start of the Q&A section\n",
        "  qna_start_patterns = [\n",
        "    \"Estamos abertos para perguntas que vocês possam ter\",\n",
        "    'Era basicamente isso que a gente tinha para falar, então a gente pode ir agora para as perguntas',\n",
        "    \"Encerrando a apresentação, eu gostaria agora de abrir para Perguntas e Respostas\"\n",
        "  ]\n",
        "\n",
        "  # Join all patterns into a single regex pattern\n",
        "  pattern = r\"|\".join(qna_start_patterns)\n",
        "\n",
        "  match = re.search(pattern, text, re.IGNORECASE)\n",
        "  if match:\n",
        "      split_index = match.start()\n",
        "      presentation = text[:split_index].strip()\n",
        "      qna = text[split_index:].strip()\n",
        "      return presentation, qna\n",
        "  else:\n",
        "      return text, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wnpspKisMqdT",
        "outputId": "fb234a30-e186-4673-af01-08fc2eda2320"
      },
      "outputs": [],
      "source": [
        "transcript_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Transcripts/'\n",
        "transcript_text_folder = \"/content/drive/MyDrive/Portfolio Projects/Mestrado/transcricoes_processadas/\"\n",
        "\n",
        "global_stats = pd.DataFrame()\n",
        "\n",
        "#Recupera os arquivos que estão na pasta\n",
        "files = os.listdir(transcript_folder)\n",
        "files = files[0:2]\n",
        "\n",
        "num_files = len(files)\n",
        "for i, file in enumerate(files):\n",
        "    path_transcription = transcript_folder + file\n",
        "\n",
        "    file_name_parts = file.split(\"-\")\n",
        "    ticker          = file_name_parts[0].strip()\n",
        "    trimestre       = file_name_parts[2].strip()\n",
        "\n",
        "    path_folder_ticker = os.path.join(transcript_text_folder, ticker)\n",
        "\n",
        "    print(path_folder_ticker, ticker, trimestre)\n",
        "    print('path_transcription', path_transcription)\n",
        "    if not os.path.exists(path_folder_ticker):\n",
        "        os.mkdir(path_folder_ticker)\n",
        "\n",
        "    print('is_file',os.path.isfile(path_transcription))\n",
        "    if os.path.isfile(path_transcription):\n",
        "      print(f\"Processando arquivo {i+1} de {num_files}\")\n",
        "\n",
        "      print(\"*** Extraindo texto do PDF: \"+ file)\n",
        "      path_transcription = transcript_folder + file\n",
        "      if ticker in ['bbas', 'bbdc']:\n",
        "          page_data = raw_text_extract(path_transcription)\n",
        "      else:\n",
        "          page_data = raw_text_extract(path_transcription, include_tables=True, include_images=False)\n",
        "\n",
        "      #print(page_data)\n",
        "\n",
        "      print(\"*** Limpando o texto\")\n",
        "      text = \" \".join(page_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3yibbaQgK78"
      },
      "outputs": [],
      "source": [
        "presentation, qna = split_text(clean(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "8L4blThNgmMw",
        "outputId": "4088cde8-9524-4b05-e359-7c09ac4e889f"
      },
      "outputs": [],
      "source": [
        "(clean(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jjs5qQirgSSb",
        "outputId": "065ed200-9fd2-4020-f67e-3fa130bb3ff3"
      },
      "outputs": [],
      "source": [
        "presentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "FDR6bTbdgXrD",
        "outputId": "0f1c7bdd-e5e0-4796-b668-2cf83e61b007"
      },
      "outputs": [],
      "source": [
        "qna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBasz2_oE-6L"
      },
      "source": [
        "#### ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cThhLuaO5T-1"
      },
      "source": [
        "#### Call openai API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwQsWHJ2E7vs"
      },
      "outputs": [],
      "source": [
        "#!pip install openai\n",
        "#!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet\n",
        "import openai\n",
        "api_key = \"fake_key\"\n",
        "openai.api_key = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbDhNWh1VVuU",
        "outputId": "792be8ff-f184-4e8e-8039-2c5113012ab9"
      },
      "outputs": [],
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i0TB9n-FGGo"
      },
      "outputs": [],
      "source": [
        "# Define the function to evaluate the text with a prompt\n",
        "def evaluate_text_with_prompt(text, prompt, model=\"gpt-4-turbo\"):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você deve concentrar os outputs para serem estritamente o que pedi, pois vou usá-los para códigos em pipeline\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7zbQY05X8U"
      },
      "source": [
        "#### First Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Kxc3owRQFGrF",
        "outputId": "cb490bb2-c4c8-4c99-dc6d-98b6d1e69015"
      },
      "outputs": [],
      "source": [
        "transcript_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Transcripts/'\n",
        "transcript_text_folder = \"/content/drive/MyDrive/Portfolio Projects/Mestrado/Generated Text 2/\"\n",
        "\n",
        "#Recupera os arquivos que estão na pasta\n",
        "files = os.listdir(transcript_text_folder)\n",
        "files = sorted(files)\n",
        "\n",
        "cutoff = {}\n",
        "\n",
        "#banco do brasil: files[59:125]\n",
        "for file_path in files:\n",
        "#for file_path in files[0:2]:\n",
        "  print('file_path',file_path)\n",
        "  path_transcription = transcript_text_folder + file_path\n",
        "\n",
        "  file_name_parts = file_path.split(\"-\")\n",
        "  ticker          = file_name_parts[0].strip()\n",
        "  ano             = file_name_parts[1].strip()\n",
        "  trimestre       = file_name_parts[2].strip()[0]\n",
        "\n",
        "  print(ticker,ano,trimestre)\n",
        "  #print('path_transcription',path_transcription)\n",
        "\n",
        "  with open(path_transcription, 'r') as file:\n",
        "    text_content = file.read()\n",
        "\n",
        "    # Example prompt\n",
        "    prompt = f\"\"\"\n",
        "      Você poderia indicar o trecho do texto que posso usar como cutoff para separar o texto da apresentação e o das perguntas e repostas (Q&A)?\n",
        "\n",
        "      Por favor não inclua nada do enunciado na resposta, apenas o trecho do texto até a primeira pontuação do Q&A.\n",
        "    \"\"\"\n",
        "\n",
        "    print(text_content, prompt)\n",
        "\n",
        "    response = evaluate_text_with_prompt(text_content, prompt) #evaluate_text_with_prompt(before_text, prompt)\n",
        "    print(ticker, ano, trimestre, response)\n",
        "\n",
        "    cutoff[f'{ticker}-{ano}-{trimestre}'] = response\n",
        "\n",
        "df_cutoff = pd.DataFrame.from_dict(cutoff, orient='index', columns=['cutoff'])\n",
        "df_cutoff.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACzYtNTp5jJl"
      },
      "source": [
        "#### First Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKDYaMdheAFk"
      },
      "outputs": [],
      "source": [
        "lis = list(df_cutoff.cutoff)\n",
        "file_path = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Temp'\n",
        "df_cutoff.to_csv(f'{file_path}/df_cutoff_raw.csv', index=True)\n",
        "#lis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuIHmiwI51OL"
      },
      "source": [
        "#### Validate cutoffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "otol6fGofgNy",
        "outputId": "f4d38d76-5087-4bfa-fce0-0c81107a0754"
      },
      "outputs": [],
      "source": [
        "for i in range(300,350): #len(lis)):\n",
        "  print(i, lis[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tj8dirxhc2EP",
        "outputId": "1930a6d2-006d-401a-a313-fc61eef27b64"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "df_cutoff['revision'] = 0\n",
        "for index, row in df_cutoff.iterrows():\n",
        "  i = i+1\n",
        "  print(i+1)\n",
        "\n",
        "      # Example prompt\n",
        "  prompt = f\"\"\"\n",
        "    Você poderia me indicar se o trecho indica que ainda haverá uma fala antes do início da sessão de perguntas e resposta?\n",
        "\n",
        "    Gostaria que a resposta viesse como uma opção binária: (Sim) ou (Não).\n",
        "  \"\"\"\n",
        "\n",
        "  print(text_content, prompt)\n",
        "\n",
        "  response = evaluate_text_with_prompt(row['cutoff'], prompt) #evaluate_text_with_prompt(before_text, prompt)\n",
        "  print(ticker, ano, trimestre, response)\n",
        "\n",
        "  df_cutoff.loc[index,'revision'] = response\n",
        "\n",
        "df_cutoff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NVE8DGXQikMz",
        "outputId": "7d35a9bd-fb3a-4e89-d005-925640cc4ead"
      },
      "outputs": [],
      "source": [
        "df_cutoff['revision'] = df_cutoff['revision'].apply(lambda x: x[1:] if x[0] == '(' else x).apply(lambda x: x[:-1] if x[-1] == ')' else x).apply(lambda x: x[:-1] if x[-1] == '.' else x)\n",
        "df_cutoff = df_cutoff.reset_index().rename(columns={'index':'doc'},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il3vIKO26eFZ"
      },
      "source": [
        "#### Second Validation and Section extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "5rbDN-eEqOfR",
        "outputId": "72608459-d9c7-4797-d960-aac97da0dad9"
      },
      "outputs": [],
      "source": [
        "transcript_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Transcripts/'\n",
        "transcript_text_folder = \"/content/drive/MyDrive/Portfolio Projects/Mestrado/Generated Text 2/\"\n",
        "\n",
        "#Recupera os arquivos que estão na pasta\n",
        "files = os.listdir(transcript_text_folder)\n",
        "files = sorted(files)\n",
        "\n",
        "revision_list = list(df_cutoff[df_cutoff['revision'] == 'Sim']['doc'])\n",
        "\n",
        "revised_cutoff = {}\n",
        "\n",
        "for file_path in files:\n",
        "  print('file_path',file_path)\n",
        "  path_transcription = transcript_text_folder + file_path\n",
        "\n",
        "  file_name_parts = file_path.split(\"-\")\n",
        "  print(file_name_parts)\n",
        "  ticker          = file_name_parts[0].strip()\n",
        "  ano             = file_name_parts[1].strip()\n",
        "  trimestre       = file_name_parts[2].strip()[0]\n",
        "\n",
        "  if f'{ticker}-{ano}-{trimestre}' in revision_list:\n",
        "    print(ticker,ano,trimestre, 'YES')\n",
        "\n",
        "    with open(path_transcription, 'r') as file:\n",
        "      text_content = file.read()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "      Você poderia indicar o trecho do texto que posso usar como cutoff para separar o texto da apresentação e o das perguntas e repostas (Q&A)?\n",
        "\n",
        "      Certifique-se de que não haja nenhuma seção depois do trecho e antes das perguntas e respostas. Mesmo que seja apenas um comentário ou última explicação.\n",
        "\n",
        "      Se o trecho anunciar que haverá alguma fala antes das perguntas e respostas ele não está correto.\n",
        "\n",
        "      Por favor não inclua nada do enunciado na resposta, apenas o trecho do texto até a primeira pontuação do Q&A.\n",
        "    \"\"\"\n",
        "\n",
        "    print(text_content, prompt)\n",
        "\n",
        "    response = evaluate_text_with_prompt(text_content, prompt) #evaluate_text_with_prompt(before_text, prompt)\n",
        "    print(ticker, ano, trimestre, response)\n",
        "\n",
        "    revised_cutoff[f'{ticker}-{ano}-{trimestre}'] = response\n",
        "\n",
        "df_revised_cutoff = pd.DataFrame.from_dict(revised_cutoff, orient='index', columns=['cutoff'])\n",
        "df_revised_cutoff.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKDrUCZG6850"
      },
      "source": [
        "Merge 1st and 2nd try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mEf2bKK31F4a",
        "outputId": "416cf924-591d-4c4b-cdbd-1a745f0dc5a2"
      },
      "outputs": [],
      "source": [
        "df_revised_cutoff = df_revised_cutoff.reset_index().rename(columns={'index':'doc'})\n",
        "df_cutoff_merge = df_cutoff.merge(df_revised_cutoff, on='doc', how='left', suffixes=('_original', '_revised'))\n",
        "df_cutoff_merge['cutoff_revised'] = df_cutoff_merge.apply(lambda x: x['cutoff_revised'] if x['revision'] == 'Sim' else x['cutoff_original'],axis=1)\n",
        "df_cutoff_merge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1SLKJLX5IqH"
      },
      "source": [
        "#### Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T0c-64gLjlt"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Temp'\n",
        "df_cutoff.to_csv(f'{file_path}/df_cutoff_merge.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oiSuBA3qMdRx",
        "outputId": "a6ccd2a4-63f2-4491-c3ee-71b9eb1ee0bd"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Temp/df_cutoff_merge.csv'\n",
        "df_cutoff_merge = pd.read_csv(file_path).drop(columns=df_cutoff_merge.columns[0], axis=1)\n",
        "df_cutoff_merge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_hloe1m5LvT"
      },
      "source": [
        "#### Third Revision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH2pE8KSCHrW"
      },
      "outputs": [],
      "source": [
        "df_cutoff_merge['cutoff_manual'] = 0\n",
        "df_cutoff_merge.iloc[12,1] = \"PERGUNTAS & RESPOSTAS\"\n",
        "df_cutoff_merge.iloc[25,1] = \"Q&A\"\n",
        "df_cutoff_merge.iloc[56,1] = \"Sessão de Q&A\"\n",
        "df_cutoff_merge.iloc[116,1] = \"Senhoras e senhores, iniciaremos a sessão de perguntas e respostas.\"\n",
        "df_cutoff_merge.iloc[119,1] = \"Sessão de Perguntas e Respostas\"\n",
        "df_cutoff_merge.iloc[124,1] = \"Agora me junto ao Cassiano e ao Firetti para a sessão de perguntas e respostas.\"\n",
        "df_cutoff_merge.iloc[137,1] = \"Obrigada. Iniciaremos agora a sessão de perguntas e respostas.\"\n",
        "df_cutoff_merge.iloc[150,1] = \"Obrigado pela atenção de todos até o momento e passamos agora para a seção de perguntas e respostas\"\n",
        "df_cutoff_merge.iloc[157,1] = \"Finalizo por aqui essa primeira parte da reunião e vou me juntar ao Firetti no outro estúdio para seguirmos para a sessão de perguntas\"\n",
        "df_cutoff_merge.iloc[200,1] = \"Não existe\"\n",
        "df_cutoff_merge.iloc[201,1] = \"Nós estamos então à disposição às perguntas dos analistas.\"\n",
        "df_cutoff_merge.iloc[203,1] = \"Essas foram algumas considerações básicas que gostaríamos de fazer, e estamos à disposição, então, para eventuais perguntas\"\n",
        "df_cutoff_merge.iloc[219,1] = \"Agradecemos o interesse dos senhores e senhoras, e ficamos à disposição dos questionamentos\"\n",
        "df_cutoff_merge.iloc[247,1] = \"Então, basicamente é isso. Agradeço a todos a presença e aguardo questionamentos. Muito obrigado\"\n",
        "df_cutoff_merge.iloc[330,1] = \"Não existe\"\n",
        "df_cutoff_merge.iloc[376,1] = \"Com isso, eu concluo a minha apresentação. Acho que o André e eu podemos passar para a sessão de perguntas e respostas. Muito obrigado\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a25COHRlsFx"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "df_cutoff['revision'] = 0\n",
        "for index, row in df_cutoff.iterrows():\n",
        "  i = i+1\n",
        "  print(i+1)\n",
        "\n",
        "      # Example prompt\n",
        "  prompt = f\"\"\"\n",
        "    Você poderia me indicar se o trecho indica que ainda haverá uma fala antes do início da sessão de perguntas e resposta?\n",
        "\n",
        "    Gostaria que a resposta viesse como uma opção binária: (Sim) ou (Não).\n",
        "  \"\"\"\n",
        "\n",
        "  print(text_content, prompt)\n",
        "\n",
        "  response = evaluate_text_with_prompt(row['cutoff'], prompt) #evaluate_text_with_prompt(before_text, prompt)\n",
        "  print(ticker, ano, trimestre, response)\n",
        "\n",
        "  df_cutoff.loc[index,'revision'] = response\n",
        "\n",
        "df_cutoff.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsp3BwIx7-wV"
      },
      "source": [
        "#### Last Revision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXKL6xbS8EUZ"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Temp/df_cutoff_merge - antigo.csv'\n",
        "df_cutoff_merge = pd.read_csv(file_path)\n",
        "df_cutoff_merge.drop(columns=df_cutoff_merge.columns[0], axis=1)\n",
        "df_cutoff_merge.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roq_rsGW8iFk"
      },
      "outputs": [],
      "source": [
        "# Example folder paths\n",
        "transcript_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Transcripts/'\n",
        "\n",
        "# Suppose these are your files\n",
        "files = os.listdir(transcript_folder)\n",
        "files = files#[:10]  # Just first 10 as an example\n",
        "\n",
        "def process_single_file(file_name, df_cutoff_merge):\n",
        "    \"\"\"\n",
        "    Worker function that processes a single file.\n",
        "    Returns a dictionary with doc name, 'presentation', 'qna' segments, and their lengths.\n",
        "    \"\"\"\n",
        "    path_transcription = os.path.join(transcript_folder, file_name)\n",
        "\n",
        "    # Split file name to extract relevant parts\n",
        "    file_name_parts = file_name.split(\"-\")\n",
        "    ticker    = file_name_parts[0].strip()\n",
        "    ano       = file_name_parts[1].strip()\n",
        "    trimestre = file_name_parts[2].strip()\n",
        "\n",
        "    # Decide on how to call raw_text_extract based on ticker\n",
        "    if ticker in ['bbas', 'bbdc']:\n",
        "        page_data = raw_text_extract(path_transcription)\n",
        "    else:\n",
        "        page_data = raw_text_extract(path_transcription, include_tables=True, include_images=False)\n",
        "\n",
        "    # JOIN the list of lines/pages into a single string\n",
        "    text = \" \".join(page_data)\n",
        "\n",
        "    # Build the doc_name for lookup in df_cutoff_merge\n",
        "    doc_name = f'{ticker}-{ano}-{trimestre[0]}'\n",
        "\n",
        "    # Retrieve the cutoff pattern for this doc\n",
        "    # IMPORTANT: Make sure doc_name actually matches something in df_cutoff_merge\n",
        "    # e.g. 'bbas-:2023-1'\n",
        "    cutoff_rows = df_cutoff_merge[df_cutoff_merge['doc'] == doc_name]\n",
        "    if len(cutoff_rows) == 0:\n",
        "        # If no matching row, skip or handle logic\n",
        "        # For now, treat entire text as presentation\n",
        "        return {\n",
        "            'doc': doc_name,\n",
        "            'presentation': text,\n",
        "            'qna': None,\n",
        "            'presentation_len': len(text),\n",
        "            'qna_len': 0\n",
        "        }\n",
        "\n",
        "    cutoff_str = cutoff_rows['joint_cutoff'].values[0]\n",
        "    print(doc_name, cutoff_str)\n",
        "\n",
        "    # Escape special regex chars to avoid unbalanced parentheses or similar\n",
        "    pattern = re.escape(cutoff_str)\n",
        "\n",
        "    # Search for the pattern in the text\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        split_index = match.start()\n",
        "        presentation = text[:split_index].strip()\n",
        "        qna = text[split_index:].strip()\n",
        "    else:\n",
        "        # If no match, entire text is 'presentation'\n",
        "        presentation = text\n",
        "        qna = None\n",
        "\n",
        "    # Create a row-like dictionary\n",
        "    new_row = {\n",
        "        'doc': doc_name,\n",
        "        'cutoff': cutoff_str,\n",
        "        'presentation': presentation,\n",
        "        'qna': qna,\n",
        "        'presentation_len': len(presentation),\n",
        "        'qna_len': len(qna) if qna else 0\n",
        "    }\n",
        "    return new_row\n",
        "\n",
        "# Prepare an empty DataFrame to gather results\n",
        "df_divided = pd.DataFrame(columns=['doc','presentation','qna','presentation_len','qna_len'])\n",
        "\n",
        "num_files = len(files)\n",
        "texts_as_strings = []\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "    # Use functools.partial to pass df_cutoff_merge\n",
        "    process_func = partial(process_single_file, df_cutoff_merge=df_cutoff_merge)\n",
        "\n",
        "    # Executor map returns an iterator of dictionaries (one per file)\n",
        "    results = executor.map(process_func, files)\n",
        "\n",
        "    for i, row_dict in enumerate(results, start=1):\n",
        "        print(f\"Processed file {i} of {num_files}\")\n",
        "\n",
        "        # row_dict is the dictionary returned by process_single_file\n",
        "        # We can build texts_as_strings if needed\n",
        "        presentation_text = row_dict['presentation'] if row_dict['presentation'] else \"\"\n",
        "        qna_text = row_dict['qna'] if row_dict['qna'] else \"\"\n",
        "        combined_text = presentation_text + \" \" + qna_text\n",
        "        texts_as_strings.append(combined_text)\n",
        "\n",
        "        # Append row to df_divided\n",
        "        df_divided = pd.concat([df_divided, pd.DataFrame([row_dict])], ignore_index=True)\n",
        "\n",
        "print(\"All files processed.\")\n",
        "print(df_divided.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op6GBDMu8rI3"
      },
      "outputs": [],
      "source": [
        "df_divided['cutoff_revised'] = df_divided['cutoff']\n",
        "#abcb\n",
        "df_divided.iloc[226,6] = 'É basicamente isso, estamos abertos para perguntas que vocês possam ter.'\n",
        "#bbas\n",
        "df_divided.iloc[22,6]  = 'Operadora: Obrigada. Com licença, iniciaremos agora a sessão de perguntas e respostas.'\n",
        "df_divided.iloc[283,6] = 'OPERADORA – Senhoras e senhores, iniciaremos agora a sessão de perguntas e respostas. Para fazer uma pergunta, por favor, digitem *1.'\n",
        "df_divided.iloc[253,6] = 'OPERADORA – Senhoras e senhores, iniciaremos agora a Sessão de Perguntas e Respostas. Para fazer uma pergunta, por favor, digitem *1.'\n",
        "df_divided.iloc[347,6] = 'OPERADORA- Senhoras e senhores, iniciaremos agora a sessão de perguntas e respostas.'\n",
        "df_divided.iloc[143,6] = 'OPERADORA – Obrigada. Iniciaremos agora a sessão de perguntas e respostas'\n",
        "df_divided.iloc[215,6] = 'Agora me junto ao Cassiano e ao Firetti para a sessão de perguntas e respostas.'\n",
        "#bmgb\n",
        "df_divided.iloc[191,6] = 'gostaria de abrir para sessões de perguntas e respostas'\n",
        "df_divided.iloc[295,6] = 'Danilo, abro agora a sessão de perguntas.'\n",
        "df_divided.iloc[92,6]  = 'isso, encerro também a apresentação e abro para a sessão de perguntas.'\n",
        "df_divided.iloc[131,6]  = 'Com isso, encerramos a nossa apresentação e vamos passar para perguntas e respostas'\n",
        "df_divided.iloc[383,6]  = 'Com isso, encerramos aqui a nossa apresentação e vamos abrir agora para perguntas'\n",
        "df_divided.iloc[219,6]  = 'Dessa forma, eu encerro aqui a apresentação de resultados do Banco Bmg e'\n",
        "df_divided.iloc[9,6]  = 'Encerro aqui a apresentação. Iniciaremos a nossa sessão de perguntas e respostas'\n",
        "df_divided.iloc[296,6]  = 'E assim, eu encerro aqui a apresentação de resultados, para iniciarmos a sessão, agora'\n",
        "df_divided.iloc[352,6]  = 'Vamos passar para o Q&A agora.'\n",
        "df_divided.iloc[89,6]  = 'E assim, eu encerro a apresentação e gostaria de abrir para sessões de perguntas'\n",
        "#bpan\n",
        "df_divided.iloc[274,6]  = 'E aí, com isso, a gente encerra os slides e pode começar o nosso Q&A com os analistas e investidores'\n",
        "#banrisul\n",
        "df_divided.iloc[90,6]  = 'Então, acho que era isso que eu queria comentar, e estamos à disposição para perguntas dos senhores'\n",
        "df_divided.iloc[6,6]  = 'Eram essas as observações que eu tinha a fazer, e agora aguardamos os questionamentos para ver as questões que nós podemos clarear. Obrigado'\n",
        "df_divided.iloc[113,6]  = 'Vou encerrar por enquanto, e o grupo aqui ficará à disposição para eventuais perguntas de quem está nos prestigiando aqui hoje. Muito obrigado.'\n",
        "df_divided.iloc[236,6]  = 'eu só queria fazer isso com essa consideração final e já podemos passar, então, para as perguntas e respostas.'\n",
        "df_divided.iloc[66,6]  = 'Com isso, a apresentação em si se encerra e devolvemos a palavra aos senhores e às senhoras para as perguntas que desejarem. Ficamos à vontade.'\n",
        "df_divided.iloc[19,6]  = 'Com isso, eu encerro a discussão dos principais números, e nós nos colocamos à disposição dos analistas para os questionamentos que houver. Obrigado.'\n",
        "df_divided.iloc[204,6]  = 'Com isso, vamos passar para a parte dos questionamentos do mercado, para'\n",
        "df_divided.iloc[199,6]  = 'E agradeço a todos pela participação nessa áudioconferência. Obrigado'\n",
        "df_divided.iloc[323,6]  = 'Com isso aqui eu encerro a apresentação e devolvo para a continuidade da nossa reunião.'\n",
        "#itub\n",
        "df_divided.iloc[188,6]  = 'Com isso encerramos a apresentação e estamos aqui abertos todos nós para as perguntas que vocês quiserem fazer.'\n",
        "df_divided.iloc[85,6]  = 'Com isso eu encerro a apresentação. Nós estamos aqui todos abertos às perguntas que vocês queiram fazer.'\n",
        "df_divided.iloc[310,6]  = 'Essas são as telas que a gente estaria apresentando, agora estamos abertos às perguntas de vocês.'\n",
        "df_divided.iloc[162,6]  = 'Muito bem, tendo dito tudo isto, eu estou abrindo para perguntas e obrigado aí pela atenção de vocês.'\n",
        "df_divided.iloc[355,6]  = 'Com isso eu encerro aqui a apresentação e estaremos a partir de agora, o Marcelo Kopel e eu, à disposição para responder eventuais perguntas. Obrigado.'\n",
        "df_divided.iloc[291,6]  = 'Bem, com estas projeções, eu concluo a apresentação e nós podemos passar para as perguntas e respostas.'\n",
        "df_divided.iloc[4,6]  = 'Com isso, nós concluímos esta apresentação e estamos abertos agora a qualquer questão que vocês possam ter. Muito obrigado.'\n",
        "df_divided.iloc[194,6]  = 'Com isto, eu concluo a apresentação, estou aberto para qualquer dúvida que vocês possam ter. Muito obrigado.'\n",
        "df_divided.iloc[250,6]  = 'Com isso, nós concluímos esta apresentação e estamos abertos agora a qualquer questão que vocês possam ter. Muito obrigado.'\n",
        "df_divided.iloc[232,6]  = 'E, com isso, eu encerro aqui a apresentação e abro para perguntas.'\n",
        "df_divided.iloc[322,6]  = 'chamar o Renato de volta para me ajudar com a sessão de perguntas e respostas.'\n",
        "df_divided.iloc[377,6]  = 'Agora vou para o nosso Perguntas e Respostas, vou me juntar ao Renato. Nos vemos'\n",
        "#prbc\n",
        "df_divided.iloc[234,6]  = 'Não existe'\n",
        "df_divided.iloc[177,6]  = 'Operador: Nossa primeira pergunta vem do senhor Francisco do banco Safra.'\n",
        "#santander\n",
        "df_divided.iloc[251,6]  = 'Então, muito obrigado pela sua atenção. Quando vocês quiserem, podemos'\n",
        "df_divided.iloc[38,6]  = 'Bom dia. Será que vocês poderiam nos dar um pouco mais de detalhe da natureza'\n",
        "df_divided.iloc[329,6]  = 'Com isso, eu concluo, e creio que agora teremos nossa sessão de perguntas e respostas. Muito obrigado.'\n",
        "df_divided.iloc[218,6]  = 'Obrigado por sua atenção e agora estamos disponíveis para responder às suas perguntas.'\n",
        "df_divided.iloc[245,6]  = 'Eu gostaria de agradecer a todos pela atenção. Agora podemos iniciar a sessão de perguntas e respostas.'\n",
        "df_divided.iloc[17,6]  = 'Gostaria de agradecer a todos pela atenção e ficamos à disposição responder as suas perguntas'\n",
        "df_divided.iloc[195,6]  = 'Então, era isso, em poucas palavras, que eu queria compartilhar com vocês, e acho que agora podemos abrir a sessão para perguntas e respostas.'\n",
        "df_divided.iloc[21,6]  = 'Com isso, faço uma pausa e teremos, acredito, meia hora para perguntas e respostas'\n",
        "#abcb\n",
        "df_divided.iloc[102,6]  = 'Esses eram os principais fatos que a gente gostaria de apresentar, e nos colocamos à disposição para qualquer dúvida ou qualquer pergunta'\n",
        "df_divided.iloc[197,6]  = 'a gente tinha para apresentar, a gente abre para qualquer dúvida, pra qualquer pergunta, ahn, que, que seja necessária. Obrigado.'\n",
        "df_divided.iloc[87,6]  = 'Isso é basicamente o que a gente apostou, então a partir de agora a gente abre para responder às perguntas que vocês'\n",
        "df_divided.iloc[109,6]  = 'Oi pessoal, é o Thiago Baptista. Eu tenho 2 perguntas. A primeira em relação as margens'\n",
        "df_divided.iloc[357,6]  = 'Estes são os dados que gostaríamos de apresentar. Nos colocamos agora à disposição para responder'\n",
        "df_divided.iloc[171,6]  = 'Para participar é só levantar a mão clicando no ícone na parte inferior da tela'\n",
        "df_divided.iloc[64,6]  = 'transmissão. Agora, como mencionado, abriremos a seção de perguntas e respostas.'\n",
        "#bbas\n",
        "df_divided.iloc[137,6]  = 'Essas eram as considerações sobre detalhamento dos resultados. Gostaríamos agora de abrir a teleconferência para a sessão de perguntas e respostas'\n",
        "df_divided.iloc[220,6]  = 'Agora podemos abrir a sessão de perguntas e respostas, e ficamos à disposição'\n",
        "df_divided.iloc[269,6]  = 'Essas eram praticamente as informações que nós gostaríamos de compartilhar com vocês. Podemos agora abri para a sessão de perguntas e respostas. Muito obrigada.'\n",
        "df_divided.iloc[373,6]  = 'Nossa primeira pergunta vem do senhor Eduardo Rosman, do Banco'\n",
        "df_divided.iloc[255,6]  = 'Agradeço agora a presença de todos e podemos seguir para a sessão de perguntas e respostas'\n",
        "df_divided.iloc[261,6]  = 'E agora agradeço a participação de todos e podemos iniciar a sessão de perguntas e respostas'\n",
        "df_divided.iloc[115,6]  = 'Assim eu finalizo aqui a apresentação dos nossos números e gostaria de abrir, então para o nosso Q&A. Agradeço aí o tempo e a atenção'\n",
        "#bbdc\n",
        "df_divided.iloc[185,6]  = 'Muito obrigado pela participação de todos que estão conectados em nossa teleconferência, e a partir de agora estamos à disposição'\n",
        "df_divided.iloc[70,6]  = 'Obrigada. Iniciaremos agora a sessão de perguntas e respostas. Para fazer uma pergunta, por favor, digitem “*1”, e se quiser retirar a pergunta da lista'\n",
        "df_divided.iloc[208,6]  = 'Muito obrigado pela atenção das senhoras e dos senhores e passamos agora para a seção de perguntas e respostas. Muito obrigado'\n",
        "df_divided.iloc[218,6]  = 'Obrigado pela atenção de todos até o momento e passamos agora para a seção de perguntas e respostas'\n",
        "df_divided.iloc[135,6]  ='Finalizo por aqui essa primeira parte da reunião e vou me juntar ao Firetti no outro estúdio para seguirmos para a sessão de perguntas e respostas'\n",
        "#bmgb\n",
        "df_divided.iloc[110,6]  = 'Com isso eu finalizo a nossa apresentação, nossos slides, e abrimos agora para perguntas de vocês.'\n",
        "df_divided.iloc[287,6]  = 'Com isso, encerro aqui a apresentação. Agora vamos abrir para as perguntas de vocês.'\n",
        "#brsr\n",
        "df_divided.iloc[68,6]  = 'Eu gostaria de encerrar por enquanto, e colocar então à disposição para eventuais perguntas que os analistas tenham a nos fazer. Muito obrigado até o momento.'\n",
        "df_divided.iloc[210,6]  = 'São dois comentários importantes que eu gostaria de fazer antes de encaminhar as perguntas e respostas. Nós estamos então à disposição às perguntas dos analistas'\n",
        "df_divided.iloc[154,6]  = 'Essas foram algumas considerações básicas que gostaríamos de fazer, e estamos à disposição, então, para eventuais perguntas. Obrigado.'\n",
        "df_divided.iloc[242,6]  = 'Com isso concluímos a apresentação dos resultados desse 1S. Quero agradecer mais uma vez o interesse e a atenção de todos, e dizer que a partir'\n",
        "df_divided.iloc[228,6]  = 'nossa área de RI em contato permanente para poder fornecer dados também por escrito, via email, etc. Então, aguardamos as questões dos senhores.'\n",
        "df_divided.iloc[158,6]  = 'aos senhores e senhoras, para que possamos atendê-los nas demandas que houver. Vamos para a sessão de perguntas e respostas, então. Obrigado.'\n",
        "df_divided.iloc[100,6]  = 'Então, basicamente é isso. Agradeço a todos a presença e aguardo questionamentos. Muito obrigado.'\n",
        "df_divided.iloc[231,6]  = 'Iniciaremos nossa sessão de perguntas e respostas, que contará com a participação do Sr.Nathan Meneguzzi'\n",
        "#itub\n",
        "df_divided.iloc[151,6]  = 'Acho que é isso. Podemos abrir aqui para perguntas. Então, vamos a elas.'\n",
        "df_divided.iloc[336,6]  = 'E, com isso, eu termino a apresentação de resultados e abro para perguntas e respostas'\n",
        "df_divided.iloc[326,6]  = 'Está bom? Muito obrigado. Vou subir agora para o estúdio e vou encontrar com o Renato para que a gente possa continuar o nosso bate pa'\n",
        "#nu\n",
        "df_divided.iloc[302,6]  = \"Não existe\"\n",
        "df_divided.iloc[124,6]  = 'Operadora: Iniciaremos agora a sessão de perguntas e respostas para investidores e analistas'\n",
        "#prbc\n",
        "df_divided.iloc[63,6]  = \"Não Existe\"\n",
        "df_divided.iloc[298,6]  = \"Não Existe\"\n",
        "df_divided.iloc[35,6]  = \"Não Existe\"\n",
        "df_divided.iloc[174,6]  = \"Não Existe\"\n",
        "df_divided.iloc[328,6]  = \"Não Existe\"\n",
        "df_divided.iloc[198,6]  = \"Não Existe\"\n",
        "#sanb\n",
        "df_divided.iloc[55,6]  = 'Sem mais, eu passo a palavra ao moderador.'\n",
        "df_divided.iloc[257,6]  = 'Muito obrigado pela sua participação, e agora abro para a sessão de perguntas e respostas.'\n",
        "df_divided.iloc[108,6]  = 'Muito obrigado e estamos disponíveis para responder perguntas agora.'\n",
        "df_divided.iloc[211,6]  = 'Com isso, eu concluo a minha apresentação. Acho que o André e eu podemos passar para a sessão de perguntas e respostas'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZBJ5j-C82XT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "from functools import partial\n",
        "\n",
        "# Example folder paths\n",
        "transcript_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Transcripts/'\n",
        "transcript_text_folder = \"/content/drive/MyDrive/Portfolio Projects/Mestrado/transcricoes_processadas_BERTopic/\"\n",
        "\n",
        "# Suppose these are your files\n",
        "files = os.listdir(transcript_folder)\n",
        "files = files#[:10]  # Just first 10 as an example\n",
        "\n",
        "def process_single_file(file_name, df_cutoff_merge):\n",
        "    \"\"\"\n",
        "    Worker function that processes a single file.\n",
        "    Returns a dictionary with doc name, 'presentation', 'qna' segments, and their lengths.\n",
        "    \"\"\"\n",
        "    path_transcription = os.path.join(transcript_folder, file_name)\n",
        "\n",
        "    # Split file name to extract relevant parts\n",
        "    file_name_parts = file_name.split(\"-\")\n",
        "    ticker    = file_name_parts[0].strip()\n",
        "    ano       = file_name_parts[1].strip()\n",
        "    trimestre = file_name_parts[2].strip()\n",
        "\n",
        "    # Decide on how to call raw_text_extract based on ticker\n",
        "    if ticker in ['bbas', 'bbdc']:\n",
        "        page_data = raw_text_extract(path_transcription)\n",
        "    else:\n",
        "        page_data = raw_text_extract(path_transcription, include_tables=True, include_images=False)\n",
        "\n",
        "    # JOIN the list of lines/pages into a single string\n",
        "    text = \" \".join(page_data)\n",
        "\n",
        "    # Build the doc_name for lookup in df_cutoff_merge\n",
        "    doc_name = f'{ticker}-{ano}-{trimestre[0]}'\n",
        "\n",
        "    # Retrieve the cutoff pattern for this doc\n",
        "    # IMPORTANT: Make sure doc_name actually matches something in df_cutoff_merge\n",
        "    # e.g. 'bbas-:2023-1'\n",
        "    cutoff_rows = df_divided[df_divided['doc'] == doc_name]\n",
        "    if len(cutoff_rows) == 0:\n",
        "        # If no matching row, skip or handle logic\n",
        "        # For now, treat entire text as presentation\n",
        "        return {\n",
        "            'doc': doc_name,\n",
        "            'presentation': text,\n",
        "            'qna': None,\n",
        "            'presentation_len': len(text),\n",
        "            'qna_len': 0\n",
        "        }\n",
        "\n",
        "    cutoff_str = cutoff_rows['cutoff_revised'].values[0]\n",
        "    print(doc_name, cutoff_str)\n",
        "\n",
        "    # Escape special regex chars to avoid unbalanced parentheses or similar\n",
        "    pattern = re.escape(cutoff_str)\n",
        "\n",
        "    # Search for the pattern in the text\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        split_index = match.start()\n",
        "        presentation = text[:split_index].strip()\n",
        "        qna = text[split_index:].strip()\n",
        "    else:\n",
        "        # If no match, entire text is 'presentation'\n",
        "        presentation = text\n",
        "        qna = None\n",
        "\n",
        "    # Create a row-like dictionary\n",
        "    new_row = {\n",
        "        'doc': doc_name,\n",
        "        'cutoff': cutoff_str,\n",
        "        'presentation': presentation,\n",
        "        'qna': qna,\n",
        "        'presentation_len': len(presentation),\n",
        "        'qna_len': len(qna) if qna else 0\n",
        "    }\n",
        "    return new_row\n",
        "\n",
        "# Prepare an empty DataFrame to gather results\n",
        "df_divided_revised = pd.DataFrame(columns=['doc','presentation','qna','presentation_len','qna_len'])\n",
        "\n",
        "num_files = len(files)\n",
        "texts_as_strings = []\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "    # Use functools.partial to pass df_cutoff_merge\n",
        "    process_func = partial(process_single_file, df_cutoff_merge=df_cutoff_merge)\n",
        "\n",
        "    # Executor map returns an iterator of dictionaries (one per file)\n",
        "    results = executor.map(process_func, files)\n",
        "\n",
        "    for i, row_dict in enumerate(results, start=1):\n",
        "        print(f\"Processed file {i} of {num_files}\")\n",
        "\n",
        "        # row_dict is the dictionary returned by process_single_file\n",
        "        # We can build texts_as_strings if needed\n",
        "        presentation_text = row_dict['presentation'] if row_dict['presentation'] else \"\"\n",
        "        qna_text = row_dict['qna'] if row_dict['qna'] else \"\"\n",
        "        combined_text = presentation_text + \" \" + qna_text\n",
        "        texts_as_strings.append(combined_text)\n",
        "\n",
        "        # Append row to df_divided\n",
        "        df_divided_revised = pd.concat([df_divided_revised, pd.DataFrame([row_dict])], ignore_index=True)\n",
        "\n",
        "print(\"All files processed.\")\n",
        "print(df_divided_revised.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab56Bi2Y87xX"
      },
      "source": [
        "### Divide Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMSUmxIH9Ap5"
      },
      "outputs": [],
      "source": [
        "general_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Divided_text/'\n",
        "if not os.path.exists(general_folder):\n",
        "    os.mkdir(general_folder)\n",
        "\n",
        "transcript_presentation_folder = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Divided_text/presentation/'\n",
        "transcript_qna_folder          = '/content/drive/MyDrive/Portfolio Projects/Mestrado/Divided_text/qna'\n",
        "\n",
        "if not os.path.exists(transcript_presentation_folder):\n",
        "    os.mkdir(transcript_presentation_folder)\n",
        "if not os.path.exists(transcript_qna_folder):\n",
        "    os.mkdir(transcript_qna_folder)\n",
        "\n",
        "count = 0\n",
        "num_files = len(df_divided_revised)\n",
        "for index, row in df_divided_revised.iterrows():\n",
        "  count += 1\n",
        "  file_name = f\"{row['doc']}.txt\"\n",
        "  print(f'Processing file {count} of {num_files}')\n",
        "\n",
        "  file_path_presentation = os.path.join(transcript_presentation_folder, file_name)\n",
        "  with open(file_path_presentation, 'w') as file:\n",
        "    file.write(row['presentation'])\n",
        "\n",
        "  if row['qna'] is not None:\n",
        "    file_path_qna = os.path.join(transcript_qna_folder, file_name)\n",
        "    with open(file_path_qna, 'w') as file:\n",
        "      file.write(row['qna'])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print('All files processed')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A_qN7WgRY417"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
